{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6b0f32",
   "metadata": {},
   "source": [
    "Eithar Elfatih Burie Abdelrahman  Batch DS2403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05acd5",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37695ba5",
   "metadata": {},
   "source": [
    "__1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8276e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open driver \n",
    "driver=webdriver.Chrome()\n",
    "#open website\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3abb90c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "#create lists for details to be scraped \n",
    "Rank_1=[]\n",
    "Name_1=[]\n",
    "Artist_1=[]\n",
    "Upload_date_1=[]\n",
    "Views_1=[]\n",
    "\n",
    "\n",
    "#2. scrap each detail and print length to assure the same \n",
    "\n",
    "try: \n",
    "    name_tags=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in name_tags:\n",
    "        name=i.text\n",
    "        Name_1.append(name)\n",
    "except NOSuchElementException:\n",
    "    name.append('No details available')\n",
    "except StaleReferenceException:\n",
    "    name.append('No details available')\n",
    "    \n",
    "    \n",
    "print(len(Name_1))\n",
    "\n",
    "try:\n",
    "    artist_tags=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in artist_tags:\n",
    "        artist=i.text\n",
    "        Artist_1.append(artist)\n",
    "except NOSuchElementException:\n",
    "    name.append('No details available')\n",
    "except StaleReferenceException:\n",
    "    name.append('No details available')\n",
    "    \n",
    "print(len(Artist_1))\n",
    "\n",
    "try:\n",
    "    upload_tags=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "    for i in upload_tags:\n",
    "        upload=i.text\n",
    "        Upload_date_1.append(upload)\n",
    "except NOSuchElementException:\n",
    "    name.append('No details available')\n",
    "except StaleReferenceException:\n",
    "    name.append('No details available')\n",
    "    \n",
    "    \n",
    "print(len(Upload_date_1))\n",
    "\n",
    "try:\n",
    "    views_tags=driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "    for i in views_tags:\n",
    "        views=i.text\n",
    "        Views_1.append(views)\n",
    "except NOSuchElementException:\n",
    "    name.append('No details available')\n",
    "except StaleReferenceException:\n",
    "    name.append('No details available')\n",
    "    \n",
    "    \n",
    "print(len(Views_1))\n",
    "\n",
    "#close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5c7f29a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[20]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Shape of You\"[25]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Learning Colors â€“ Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Masha and the Bear â€“ Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Sugar\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[42]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Counting Stars\"[43]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[46]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Sorry\"[48]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of Song  \\\n",
       "1                             \"Baby Shark Dance\"[7]   \n",
       "2                                   \"Despacito\"[10]   \n",
       "3                        \"Johny Johny Yes Papa\"[18]   \n",
       "4                                   \"Bath Song\"[19]   \n",
       "5                               \"See You Again\"[20]   \n",
       "6                                \"Shape of You\"[25]   \n",
       "7                           \"Wheels on the Bus\"[28]   \n",
       "8                 \"Phonics Song with Two Words\"[29]   \n",
       "9                                 \"Uptown Funk\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11  \"Learning Colors â€“ Colorful Eggs on a Farm\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13   \"Masha and the Bear â€“ Recipe for Disaster\"[38]   \n",
       "14                                     \"Axel F\"[39]   \n",
       "15                        \"Baa Baa Black Sheep\"[40]   \n",
       "16                                      \"Sugar\"[41]   \n",
       "17                             \"Lakdi Ki Kathi\"[42]   \n",
       "18                             \"Counting Stars\"[43]   \n",
       "19                                       \"Roar\"[44]   \n",
       "20           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "21                      \"Shree Hanuman Chalisa\"[46]   \n",
       "22          \"Humpty the train on a fruits ride\"[47]   \n",
       "23                                      \"Sorry\"[48]   \n",
       "24                          \"Thinking Out Loud\"[49]   \n",
       "25                                    \"Perfect\"[50]   \n",
       "26                                 \"Dark Horse\"[51]   \n",
       "27                                 \"Let Her Go\"[52]   \n",
       "28                                      \"Faded\"[53]   \n",
       "29                             \"Girls Like You\"[54]   \n",
       "30                                    \"Lean On\"[55]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "1         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "2                                          Luis Fonsi   January 12, 2017   \n",
       "3   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "4                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                                          Ed Sheeran   January 30, 2017   \n",
       "7                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "8               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "9                                         Mark Ronson  November 19, 2014   \n",
       "10                                                Psy      July 15, 2012   \n",
       "11                                        Miroshka TV  February 27, 2018   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Get Movies   January 31, 2012   \n",
       "14                                         Crazy Frog      June 16, 2009   \n",
       "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "16                                           Maroon 5   January 14, 2015   \n",
       "17                                       Jingle Toons      June 14, 2018   \n",
       "18                                        OneRepublic       May 31, 2013   \n",
       "19                                         Katy Perry  September 5, 2013   \n",
       "20                                            Shakira       June 4, 2010   \n",
       "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                      Justin Bieber   October 22, 2015   \n",
       "24                                         Ed Sheeran    October 7, 2014   \n",
       "25                                         Ed Sheeran   November 9, 2017   \n",
       "26                                         Katy Perry  February 20, 2014   \n",
       "27                                          Passenger      July 25, 2012   \n",
       "28                                        Alan Walker   December 3, 2015   \n",
       "29                                           Maroon 5       May 31, 2018   \n",
       "30                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "1   14.52  \n",
       "2    8.44  \n",
       "3    6.91  \n",
       "4    6.70  \n",
       "5    6.27  \n",
       "6    6.26  \n",
       "7    6.13  \n",
       "8    5.80  \n",
       "9    5.23  \n",
       "10   5.15  \n",
       "11   5.11  \n",
       "12   4.63  \n",
       "13   4.58  \n",
       "14   4.54  \n",
       "15   4.05  \n",
       "16   4.05  \n",
       "17   4.04  \n",
       "18   4.02  \n",
       "19   4.00  \n",
       "20   3.93  \n",
       "21   3.84  \n",
       "22   3.81  \n",
       "23   3.80  \n",
       "24   3.77  \n",
       "25   3.74  \n",
       "26   3.72  \n",
       "27   3.66  \n",
       "28   3.63  \n",
       "29   3.61  \n",
       "30   3.60  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=pd.DataFrame({\n",
    "    'Name of Song':Name_1,\n",
    "    'Artist':Artist_1,\n",
    "    'Upload Date':Upload_date_1,\n",
    "    'Views':Views_1,\n",
    "})\n",
    "df_1.index=df_1.index + 1\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26d294",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed1ea4",
   "metadata": {},
   "source": [
    "__2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5bff3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open chrome driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(2)\n",
    "#open wikipedia webpage to be scrapped\n",
    "driver.get('https://www.bcci.tv/.')\n",
    "time.sleep(2)# seconds\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "a3963368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click fixtures and results\n",
    "button_1=driver.find_element(By.XPATH, \"//div[@class='imw-tabs international-tabs']/a[2]\")\n",
    "button_1.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "81a73be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#create lists fot details\n",
    "Series_2=[]\n",
    "Place_2=[]\n",
    "Date_2=[]\n",
    "Time_note_2=[]\n",
    "\n",
    "#scrap details for each and print length to assure the same to create dataframe\n",
    "try:\n",
    "    series_tags=driver.find_elements(By.XPATH, \"//h5[@class='match-tournament-name ng-binding']\")\n",
    "    for i in series_tags:\n",
    "        series=i.text\n",
    "        Series_2.append(series)\n",
    "except NOSuchElementException:\n",
    "    name.append('No details available')\n",
    "\n",
    "print(len(Series_2))\n",
    "\n",
    "try:\n",
    "    place_tags=driver.find_elements(By.XPATH, \"//span[@class='ng-binding ng-scope']\")\n",
    "    for i in place_tags:\n",
    "        place=i.text\n",
    "        Place_2.append(place)\n",
    "except NOSuchElementException:\n",
    "    place.append('No details available')\n",
    "\n",
    "print(len(Place_2))\n",
    "\n",
    "try:\n",
    "    date_tags=driver.find_elements(By.XPATH, \"//div[@class='match-dates ng-binding']\")\n",
    "    for i in date_tags:\n",
    "        date=i.text\n",
    "        Date_2.append(date)\n",
    "except NOSuchElementException:\n",
    "    date.append('No details available')\n",
    "\n",
    "print(len(Date_2))\n",
    "\n",
    "try:\n",
    "    time_tags=driver.find_elements(By.XPATH, \"//div[@class='match-time no-margin ng-binding']\")\n",
    "    for i in time_tags:\n",
    "        time_=i.text\n",
    "        Time_note_2.append(time_)\n",
    "except NOSuchElementException:\n",
    "    time_.append('No details available')\n",
    "\n",
    "print(len(Time_note_2))\n",
    "\n",
    "#close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ee5246f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC Mens T20 World Cup 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>12 Jun</td>\n",
       "      <td>17:30 EEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa Women Tour Of India Warm Up Match...</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>13 Jun</td>\n",
       "      <td>11:00 EEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC Mens T20 World Cup 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 Jun</td>\n",
       "      <td>17:30 EEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa Women Tour Of India ODI Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>16 Jun</td>\n",
       "      <td>11:00 EEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa Women Tour Of India ODI Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>19 Jun</td>\n",
       "      <td>11:00 EEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Series  \\\n",
       "1                        ICC Mens T20 World Cup 2024   \n",
       "2  South Africa Women Tour Of India Warm Up Match...   \n",
       "3                        ICC Mens T20 World Cup 2024   \n",
       "4   South Africa Women Tour Of India ODI Series 2024   \n",
       "5   South Africa Women Tour Of India ODI Series 2024   \n",
       "\n",
       "                                               Place    Date        Time  \n",
       "1       Nassau County International Cricket Stadium,  12 Jun  17:30 EEST  \n",
       "2                             M Chinnaswamy Stadium,  13 Jun  11:00 EEST  \n",
       "3  Central Broward Park & Broward County Stadium,...  15 Jun  17:30 EEST  \n",
       "4                             M Chinnaswamy Stadium,  16 Jun  11:00 EEST  \n",
       "5                             M Chinnaswamy Stadium,  19 Jun  11:00 EEST  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame \n",
    "\n",
    "df_2=pd.DataFrame({\n",
    "    'Series':Series_2,\n",
    "    'Place':Place_2,\n",
    "    'Date':Date_2,\n",
    "    'Time':Time_note_2\n",
    "})\n",
    "\n",
    "#adjust index\n",
    "df_2.index=df_2.index + 1\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d707f2",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01210fc8",
   "metadata": {},
   "source": [
    "__3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "53b9b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open chrome driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(2)\n",
    "#open statisitics times webpage to be scrapped\n",
    "driver.get(' http://statisticstimes.com/ ')\n",
    "time.sleep(2)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "2a2957cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click econmy dropdown \n",
    "economy_click=driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[2]/div[2]/button/i\")\n",
    "economy_click.click()\n",
    "\n",
    "#click india link\n",
    "india_link=driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "try:\n",
    "    india_link.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(india_link.get_attribute('href'))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "396d4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click Indian states >>>GDP of Indian states\n",
    "State_link=driver.find_element(By.XPATH, '//html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "try:\n",
    "    State_link.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(State_link.get_attribute('href'))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c5145079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "66\n",
      "66\n",
      "66\n",
      "66\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "#create rank list \n",
    "Rank=[]\n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[1]\")\n",
    "for i in rank_tag:\n",
    "    rank=i.text\n",
    "    Rank.append(rank)\n",
    "\n",
    "#print length to assure all details are the same length     \n",
    "print(len(Rank))\n",
    "\n",
    "#create state list\n",
    "State=[]\n",
    "#scrape details\n",
    "state_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[2]\")\n",
    "for i in state_tag:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)\n",
    "        \n",
    "#print length to assure all details are the same length         \n",
    "print(len(State))\n",
    "\n",
    "#create 2021-2022 (18-19 not available)\n",
    "GSDP=[]\n",
    "#scrape details\n",
    "gsdp_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[5]\")\n",
    "for i in gsdp_tag:\n",
    "    if i.text is None:\n",
    "        GSDP.append('--')\n",
    "    else:\n",
    "        GSDP.append(i.text)\n",
    "print(len(GSDP))\n",
    "\n",
    "#create 2022-2023 (19-20 not available)\n",
    "GSDP_2=[]\n",
    "#scrape details\n",
    "gsdp_2_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[4]\")\n",
    "for i in gsdp_2_tag:\n",
    "    if i.text is None:\n",
    "        GSDP_2.append('--')\n",
    "    else:\n",
    "        GSDP_2.append(i.text)\n",
    "print(len(GSDP_2))\n",
    "\n",
    "#create Shares list\n",
    "Shares=[]\n",
    "#scrape details\n",
    "shares_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[6]\")\n",
    "for i in shares_tag:\n",
    "    if i.text is None:\n",
    "        Shares.append('--')\n",
    "    else:\n",
    "        Shares.append(i.text)\n",
    "print(len(Shares))\n",
    "\n",
    "#create GDP list\n",
    "Gdp=[]\n",
    "#create details\n",
    "gdp_tag=driver.find_elements(By.XPATH, \"//table[@class='display dataTable']//tbody/tr/td[7]\")\n",
    "for i in gdp_tag:\n",
    "    if i.text is None:\n",
    "        Gdp.append('--')\n",
    "    else:\n",
    "        Gdp.append(i.text)\n",
    "print(len(Gdp))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4e828c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (21-22)</th>\n",
       "      <th>GSDP old(22-23)</th>\n",
       "      <th>Shares</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP (21-22) GSDP old(22-23)  Shares  \\\n",
       "1     1                Maharashtra    3,108,022               -  13.17%   \n",
       "2     2                 Tamil Nadu    2,071,286       2,364,514   8.78%   \n",
       "3     3                  Karnataka    1,978,094       2,269,995   8.38%   \n",
       "4     4              Uttar Pradesh    1,975,595       2,258,040   8.37%   \n",
       "5     5                    Gujarat    1,928,683       2,230,609   8.17%   \n",
       "6     6                West Bengal    1,329,238       1,531,758   5.63%   \n",
       "7     7                  Rajasthan    1,193,489       1,365,849   5.06%   \n",
       "8     8             Andhra Pradesh    1,148,471       1,303,524   4.87%   \n",
       "9     9                  Telangana    1,124,204       1,308,034   4.76%   \n",
       "10   10             Madhya Pradesh    1,092,964       1,246,471   4.63%   \n",
       "11   11                     Kerala      934,542       1,046,188   3.96%   \n",
       "12   12                      Delhi      881,336       1,014,688   3.73%   \n",
       "13   13                    Haryana      868,905         984,055   3.68%   \n",
       "14   14                     Odisha      662,886         753,177   2.81%   \n",
       "15   15                      Bihar      650,302         751,396   2.76%   \n",
       "16   16                     Punjab      617,192         676,164   2.62%   \n",
       "17   17                      Assam      411,454         493,167   1.74%   \n",
       "18   18               Chhattisgarh      410,525         464,399   1.74%   \n",
       "19   19                  Jharkhand      358,863         393,722   1.52%   \n",
       "20   20                Uttarakhand      267,143         303,781   1.13%   \n",
       "21   21            Jammu & Kashmir      193,352         224,226   0.82%   \n",
       "22   22           Himachal Pradesh      172,162         191,728   0.73%   \n",
       "23   23                        Goa       84,266          93,672   0.36%   \n",
       "24   24                    Tripura       62,550          72,636   0.27%   \n",
       "25   25                 Chandigarh       46,096          54,285   0.20%   \n",
       "26   26                 Puducherry       43,810          49,643   0.19%   \n",
       "27   27                  Meghalaya       38,785          42,697   0.16%   \n",
       "28   28                     Sikkim       37,557          42,756   0.16%   \n",
       "29   29                    Manipur       36,594               -   0.16%   \n",
       "30   30          Arunachal Pradesh       34,775          39,630   0.15%   \n",
       "31   31                   Nagaland       31,038          35,643   0.13%   \n",
       "32   32                    Mizoram       27,824               -   0.12%   \n",
       "33   33  Andaman & Nicobar Islands       10,371               -   0.04%   \n",
       "\n",
       "        GDP  \n",
       "1   414.928  \n",
       "2   276.522  \n",
       "3   264.080  \n",
       "4   263.747  \n",
       "5   257.484  \n",
       "6   177.456  \n",
       "7   159.334  \n",
       "8   153.324  \n",
       "9   150.084  \n",
       "10  145.913  \n",
       "11  124.764  \n",
       "12  117.660  \n",
       "13  116.001  \n",
       "14   88.497  \n",
       "15   86.817  \n",
       "16   82.397  \n",
       "17   54.930  \n",
       "18   54.806  \n",
       "19   47.909  \n",
       "20   35.664  \n",
       "21   25.813  \n",
       "22   22.984  \n",
       "23   11.250  \n",
       "24    8.351  \n",
       "25    6.154  \n",
       "26    5.849  \n",
       "27    5.178  \n",
       "28    5.014  \n",
       "29    4.885  \n",
       "30    4.643  \n",
       "31    4.144  \n",
       "32    3.715  \n",
       "33    1.385  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame and limit to 33 for the first table only \n",
    "\n",
    "df_3=pd.DataFrame({\n",
    "    'Rank': Rank[:33],\n",
    "    'State': State[:33],\n",
    "    'GSDP (21-22)'  : GSDP[:33],\n",
    "    'GSDP old(22-23)': GSDP_2[:33],\n",
    "    'Shares': Shares[:33],\n",
    "    'GDP': Gdp[:33]\n",
    "})\n",
    "\n",
    "#close driver\n",
    "driver.close()\n",
    "\n",
    "#adjust index\n",
    "df_3.index=df_3.index + 1\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de522e",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c62881",
   "metadata": {},
   "source": [
    "__4. Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   B) Repository description   C) Contributors count   D) Language used__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f1c45be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1183d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open github webpage to be scrapped\n",
    "driver.get('https://github.com/')\n",
    "time.sleep(2)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f058c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click open source dropdown\n",
    "open_=driver.find_element(By.XPATH, (\"//ul[@class='d-lg-flex list-style-none']/li[3]\"))\n",
    "open_.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#click repositories trending link\n",
    "repo_trend=driver.find_element(By.XPATH, (\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\"))\n",
    "repo_trend.click()\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0f0ac0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16 16 16\n"
     ]
    }
   ],
   "source": [
    "#create empty lists\n",
    "Repo_name=[]\n",
    "Repo_desc=[]\n",
    "Cont_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "#find all repository titles and links\n",
    "Repo_tags=driver.find_elements(By.XPATH,  \"//h2[@class='h3 lh-condensed']/a\") #find all h2 tags \n",
    "Repo_name=[repo.text for repo in Repo_tags] # extract text from each element \n",
    "\n",
    "links_=[repo.get_attribute('href') for repo in Repo_tags]\n",
    "\n",
    "for link in links_:\n",
    "    driver.get(link)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        desc_tags=driver.find_element(By.XPATH, \"//p[@class='f4 my-3']\")\n",
    "        Repo_desc.append(desc_tags.text) \n",
    "    except NoSuchElementException:\n",
    "        Repo_desc.append('No description provided')\n",
    "        time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        count_tags=driver.find_element(By.XPATH, \"//div[@class='BorderGrid-row'][5]/div/div/a\")\n",
    "        Cont_count.append(count_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Cont_count.append('No contributors mentioned')\n",
    "        time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        lang_tags=driver.find_element(By.XPATH, \"//div[@class='BorderGrid about-margin']/div[6]/div/ul/li\")\n",
    "        Language_used.append(lang_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('No language mentioned')  \n",
    "        time.sleep(2)\n",
    "        \n",
    "print(len(Repo_name),len(Repo_desc),len(Cont_count),len(Language_used))    \n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e5b893f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REpository Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huggingface / lerobot</td>\n",
       "      <td>ðŸ¤— LeRobot: End-to-end Learning for Real-World ...</td>\n",
       "      <td>+ 6 contributors</td>\n",
       "      <td>Python\\n98.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DaoCloud / public-image-mirror</td>\n",
       "      <td>å¾ˆå¤šé•œåƒéƒ½åœ¨å›½å¤–ã€‚æ¯”å¦‚ gcr ã€‚å›½å†…ä¸‹è½½å¾ˆæ…¢ï¼Œéœ€è¦åŠ é€Ÿã€‚</td>\n",
       "      <td>+ 34 contributors</td>\n",
       "      <td>Shell\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>idootop / mi-gpt</td>\n",
       "      <td>ðŸ  å°†å°çˆ±éŸ³ç®±æŽ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±žè¯­éŸ³åŠ©æ‰‹ã€‚</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple / swift-testing</td>\n",
       "      <td>A modern, expressive testing package for Swift</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple / axlearn</td>\n",
       "      <td>An Extensible Deep Learning Library</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>codecrafters-io / build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>+ 103 contributors</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coollabsio / coolify</td>\n",
       "      <td>An open-source &amp; self-hostable Heroku / Netlif...</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>karpathy / nanoGPT</td>\n",
       "      <td>The simplest, fastest repository for training/...</td>\n",
       "      <td>+ 22 contributors</td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xenova / transformers.js</td>\n",
       "      <td>State-of-the-art Machine Learning for the web....</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>litestar-org / litestar</td>\n",
       "      <td>Production-ready, Light, Flexible and Extensib...</td>\n",
       "      <td>+ 187 contributors</td>\n",
       "      <td>Python\\n99.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>coqui-ai / TTS</td>\n",
       "      <td>ðŸ¸ðŸ’¬ - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>+ 135 contributors</td>\n",
       "      <td>Python\\n92.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3b1b / manim</td>\n",
       "      <td>Animation engine for explanatory math videos</td>\n",
       "      <td>+ 134 contributors</td>\n",
       "      <td>Python\\n96.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>juspay / hyperswitch</td>\n",
       "      <td>An open source payments switch written in Rust...</td>\n",
       "      <td>No contributors mentioned</td>\n",
       "      <td>No language mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dortania / OpenCore-Legacy-Patcher</td>\n",
       "      <td>Experience macOS just like before</td>\n",
       "      <td>+ 18 contributors</td>\n",
       "      <td>Python\\n98.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AvaloniaUI / Avalonia</td>\n",
       "      <td>Develop Desktop, Embedded, Mobile and WebAssem...</td>\n",
       "      <td>+ 396 contributors</td>\n",
       "      <td>C#\\n98.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         REpository Name  \\\n",
       "1                  huggingface / lerobot   \n",
       "2         DaoCloud / public-image-mirror   \n",
       "3                       idootop / mi-gpt   \n",
       "4   cloudcommunity / Free-Certifications   \n",
       "5                  apple / swift-testing   \n",
       "6                        apple / axlearn   \n",
       "7     codecrafters-io / build-your-own-x   \n",
       "8                   coollabsio / coolify   \n",
       "9                     karpathy / nanoGPT   \n",
       "10              xenova / transformers.js   \n",
       "11               litestar-org / litestar   \n",
       "12                        coqui-ai / TTS   \n",
       "13                          3b1b / manim   \n",
       "14                  juspay / hyperswitch   \n",
       "15    dortania / OpenCore-Legacy-Patcher   \n",
       "16                 AvaloniaUI / Avalonia   \n",
       "\n",
       "                                          Description  \\\n",
       "1   ðŸ¤— LeRobot: End-to-end Learning for Real-World ...   \n",
       "2                       å¾ˆå¤šé•œåƒéƒ½åœ¨å›½å¤–ã€‚æ¯”å¦‚ gcr ã€‚å›½å†…ä¸‹è½½å¾ˆæ…¢ï¼Œéœ€è¦åŠ é€Ÿã€‚   \n",
       "3                  ðŸ  å°†å°çˆ±éŸ³ç®±æŽ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±žè¯­éŸ³åŠ©æ‰‹ã€‚   \n",
       "4    A curated list of free courses & certifications.   \n",
       "5      A modern, expressive testing package for Swift   \n",
       "6                 An Extensible Deep Learning Library   \n",
       "7   Master programming by recreating your favorite...   \n",
       "8   An open-source & self-hostable Heroku / Netlif...   \n",
       "9   The simplest, fastest repository for training/...   \n",
       "10  State-of-the-art Machine Learning for the web....   \n",
       "11  Production-ready, Light, Flexible and Extensib...   \n",
       "12  ðŸ¸ðŸ’¬ - a deep learning toolkit for Text-to-Speec...   \n",
       "13       Animation engine for explanatory math videos   \n",
       "14  An open source payments switch written in Rust...   \n",
       "15                  Experience macOS just like before   \n",
       "16  Develop Desktop, Embedded, Mobile and WebAssem...   \n",
       "\n",
       "           Contributors Count          Language Used  \n",
       "1            + 6 contributors          Python\\n98.3%  \n",
       "2           + 34 contributors          Shell\\n100.0%  \n",
       "3   No contributors mentioned  No language mentioned  \n",
       "4   No contributors mentioned  No language mentioned  \n",
       "5   No contributors mentioned  No language mentioned  \n",
       "6   No contributors mentioned  No language mentioned  \n",
       "7          + 103 contributors  No language mentioned  \n",
       "8   No contributors mentioned                         \n",
       "9           + 22 contributors         Python\\n100.0%  \n",
       "10  No contributors mentioned                         \n",
       "11         + 187 contributors          Python\\n99.6%  \n",
       "12         + 135 contributors          Python\\n92.0%  \n",
       "13         + 134 contributors          Python\\n96.2%  \n",
       "14  No contributors mentioned  No language mentioned  \n",
       "15          + 18 contributors          Python\\n98.3%  \n",
       "16         + 396 contributors              C#\\n98.3%  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame \n",
    "\n",
    "df_3=pd.DataFrame({\n",
    "    'REpository Name':Repo_name,\n",
    "    'Description' : Repo_desc,\n",
    "    'Contributors Count':Cont_count,\n",
    "    'Language Used': Language_used\n",
    "    })\n",
    "\n",
    "#adjust index\n",
    "df_3.index=df_3.index + 1\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b2c22",
   "metadata": {},
   "source": [
    "__5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the following details:   A) Song name   B) Artist name   C) Last week rank   D) Peak rank   E) Weeks on board__  \n",
    " \n",
    "      Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "32f37bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "90ad7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open wikipedia webpage to be scrapped\n",
    "driver.get('https:/www.billboard.com/')\n",
    "time.sleep(2)\n",
    "#click billboard hot 100\n",
    "open_=driver.find_element(By.XPATH, \"//li[@class='o-nav__list-item '][1]/a\")\n",
    "open_.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e1c24a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# create lists for song title\n",
    "Song_title=[]\n",
    "try:\n",
    "    song_tags=driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li[1]/span\")#100\n",
    "    for i in song_tags:\n",
    "        Song_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song_title.append('-')\n",
    "time.sleep(2)\n",
    "#print to assure all lengths are the same\n",
    "print(len(Song_title))\n",
    "\n",
    "Artist_name=[]\n",
    "try:\n",
    "    artistn_tags=driver.find_elements(By.XPATH, \"//li[@class='lrv-u-width-100p']/ul/li/h3\")\n",
    "    for i in artistn_tags:\n",
    "        Artist_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append('-')\n",
    "time.sleep(2)   \n",
    "\n",
    "print(len(Artist_name))\n",
    "\n",
    "\n",
    "#create last week rank list\n",
    "Last_week_rank=[]\n",
    "try:#99\n",
    "    lwr_tags=driver.find_elements(By.XPATH, \"//li[@class='o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max'][2]/span\")\n",
    "    for i in lwr_tags:\n",
    "        Last_week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append('-')\n",
    "time.sleep(2) \n",
    "\n",
    "print(len(Last_week_rank))\n",
    "\n",
    "#create peak list\n",
    "Peak_rank=[]\n",
    "try:\n",
    "    pr_tags=driver.find_elements(By.XPATH, \"//li[@class='o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max'][2]\")\n",
    "    for i in pr_tags:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('-')\n",
    "time.sleep(2) \n",
    "\n",
    "print(len(Peak_rank))\n",
    "\n",
    "#create weeks on board\n",
    "Weeks_on_board=[]\n",
    "try:\n",
    "    wb_tags=driver.find_elements(By.XPATH, \"//li[@class='o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max'][2]/span\")\n",
    "    for i in wb_tags:\n",
    "        Weeks_on_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on_board.append('-')\n",
    "time.sleep(2) \n",
    "\n",
    "print(len(Weeks_on_board))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "16ceb44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Title</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post Malone Featuring Morgan Wallen</td>\n",
       "      <td>I Had Some Help</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>Houdini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy Richman</td>\n",
       "      <td>Million Dollar Baby</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaboozey</td>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kendrick Lamar</td>\n",
       "      <td>Not Like Us</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shoreline Mafia Presents OhGeesy &amp; Fenix Flexin</td>\n",
       "      <td>Heat Stick</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jason Aldean</td>\n",
       "      <td>Let Your Boys Be Country</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td>Tu Name</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>loml</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Song Title  \\\n",
       "1                Post Malone Featuring Morgan Wallen   \n",
       "2                                             Eminem   \n",
       "3                                      Tommy Richman   \n",
       "4                                          Shaboozey   \n",
       "5                                     Kendrick Lamar   \n",
       "..                                               ...   \n",
       "96                                    Tucker Wetmore   \n",
       "97   Shoreline Mafia Presents OhGeesy & Fenix Flexin   \n",
       "98                                      Jason Aldean   \n",
       "99                                     Fuerza Regida   \n",
       "100                                     Taylor Swift   \n",
       "\n",
       "                  Artist Name Last Week Rank Peak Rank Weeks on Board  \n",
       "1             I Had Some Help              1         1              4  \n",
       "2                     Houdini              2         2              1  \n",
       "3         Million Dollar Baby              2         2              6  \n",
       "4          A Bar Song (Tipsy)              3         3              8  \n",
       "5                 Not Like Us              1         1              5  \n",
       "..                        ...            ...       ...            ...  \n",
       "96          Wine Into Whiskey             77        77             11  \n",
       "97                 Heat Stick             97        97              3  \n",
       "98   Let Your Boys Be Country             98        98              1  \n",
       "99                    Tu Name             66        66             14  \n",
       "100                      loml             12        12              7  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame \n",
    "\n",
    "df_4=pd.DataFrame({\n",
    "    'Song Title':Song_title,\n",
    "    'Artist Name' : Artist_name,\n",
    "    'Last Week Rank':Last_week_rank,\n",
    "    'Peak Rank': Peak_rank,\n",
    "    'Weeks on Board': Weeks_on_board\n",
    "    })\n",
    "\n",
    "#adjust index\n",
    "df_4.index=df_4.index + 1\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a30bc",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf1ec7",
   "metadata": {},
   "source": [
    "__6. Scrape the details of Highest selling novels.   A) Book name   B) Author name   C) Volumes sold   D) Publisher   E) Genre__   \n",
    " \n",
    "      Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "625dae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a2f84ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open theguardian webpage to be scrapped\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "737179b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Book_name=[]\n",
    "try:\n",
    "    bname_tags=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']//tbody/tr/td[2]\")\n",
    "    for i in bname_tags:\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book_name.append('-')\n",
    "time.sleep(2)\n",
    "\n",
    "print(len(Book_name))\n",
    "\n",
    "Author_=[]\n",
    "try:\n",
    "    author_tags=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']//tbody/tr/td[3]\")\n",
    "    for i in author_tags:\n",
    "        Author_.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author_.append('-')\n",
    "time.sleep(2)\n",
    "\n",
    "print(len(Author_))\n",
    "\n",
    "Volumes_=[]\n",
    "try:\n",
    "    volumes_tags=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']//tbody/tr/td[4]\")\n",
    "    for i in volumes_tags:\n",
    "        Volumes_.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_.append('-')\n",
    "time.sleep(2)\n",
    "\n",
    "print(len(Volumes_))\n",
    "\n",
    "Publisher_=[]\n",
    "try:\n",
    "    publisher_tags=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']//tbody/tr/td[5]\")\n",
    "    for i in publisher_tags:\n",
    "        Publisher_.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher_.append('-')\n",
    "time.sleep(2)\n",
    "\n",
    "print(len(Publisher_))\n",
    "\n",
    "Genre_=[]\n",
    "try:\n",
    "    genre_tags=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']//tbody/tr/td[6]\")\n",
    "    for i in genre_tags:\n",
    "        Genre_.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre_.append('-')\n",
    "time.sleep(2)\n",
    "\n",
    "print(len(Genre_))\n",
    "\n",
    "#close driver\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a2cd1cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Title            Author  \\\n",
       "1                                    Da Vinci Code,The        Brown, Dan   \n",
       "2                 Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3             Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4            Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                 Fifty Shades of Grey      James, E. L.   \n",
       "..                                                 ...               ...   \n",
       "96                                           Ghost,The    Harris, Robert   \n",
       "97                      Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98               Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99   Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "    Volumes Sold        Publisher                        Genre  \n",
       "1      5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2      4,475,152       Bloomsbury           Children's Fiction  \n",
       "3      4,200,654       Bloomsbury           Children's Fiction  \n",
       "4      4,179,479       Bloomsbury           Children's Fiction  \n",
       "5      3,758,936     Random House              Romance & Sagas  \n",
       "..           ...              ...                          ...  \n",
       "96       807,311     Random House   General & Literary Fiction  \n",
       "97       794,201          Penguin        Food & Drink: General  \n",
       "98       792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99       791,507            Orion           Biography: General  \n",
       "100      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame \n",
    "\n",
    "df_6=pd.DataFrame({\n",
    "    'Book Title':Book_name,\n",
    "    'Author' : Author_,\n",
    "    'Volumes Sold':Volumes_,\n",
    "    'Publisher': Publisher_,\n",
    "    'Genre': Genre_\n",
    "})\n",
    "\n",
    "#adjust index\n",
    "df_6.index=df_6.index + 1\n",
    "df_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6291a",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2881a71",
   "metadata": {},
   "source": [
    "#WRONG\n",
    "__7. Scrape the details most watched tv series of all time from imdb.com.   \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:   \n",
    "A) Name   B) Year span   C) Genre   D) Run time   E) Ratings   F) Votes__   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "270364a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "# Open the IMDb most-watched TV series page\n",
    "driver.get('https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cea1f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250 250 250\n"
     ]
    }
   ],
   "source": [
    "#create empty lists \n",
    "\n",
    "Series_title=[]\n",
    "Year_span=[]\n",
    "Genre_=[]\n",
    "Run_time=[]\n",
    "Rating_7=[]\n",
    "Votes_7=[]\n",
    "\n",
    "for page in range (5):\n",
    "    #find all series on page\n",
    "    series_250=driver.find_elements(By.XPATH, \"//div[@class='ipc-metadata-list-summary-item__tc']\")\n",
    "    for series in series_250:\n",
    "        \n",
    "        try:                           \n",
    "            #scrap titles\n",
    "            title=series.find_element(By.XPATH, \"//div[@class='ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 iALATN dli-title']\").text\n",
    "        except NoSuchElementException:\n",
    "            title='No Title'\n",
    "        Series_title.append(title)\n",
    "            \n",
    "        try:\n",
    "            #scrap year_span\n",
    "            year=series.find_element(By.XPATH, \"//div[@class='sc-b189961a-7 feoqjK dli-title-metadata']/span[1]\").text\n",
    "        except NoSuchElementException:\n",
    "            year='No year span'\n",
    "        Year_span.append(year)\n",
    "        \n",
    "       # try:\n",
    "            #scrap genre\n",
    "        #    Genre_=series.find_element(By.XPATH, \"\").text\n",
    "        #except NoSuchElementException:\n",
    "         #   genre='No Genre given'\n",
    "        #Genre_.append(genre)\n",
    "        \n",
    "        \n",
    "        #try:\n",
    "            #scrap run_time\n",
    "         #   run_time=series.find_element(By.XPATH, \"\").text\n",
    "        #except NoSuchElementException:\n",
    "         #   run_time='No run-time available'\n",
    "        #Run_time.append(run_time)\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            #scrap rating\n",
    "            rating_=series.find_element(By.XPATH, \"//span[@class='sc-b189961a-8 kLaxqf dli-title-metadata-item'][2]\").text\n",
    "        except NoSuchElementException:\n",
    "            rating_='No run-time available'\n",
    "        Rating_7.append(rating_)\n",
    "        \n",
    "        try:\n",
    "            #scrap votes\n",
    "            votes_=series.find_element(By.XPATH, \"//span[@class='ipc-rating-star--voteCount']\").text\n",
    "        except NoSuchElementException:\n",
    "            votes_='No run-time available'\n",
    "        Votes_7.append(votes_)\n",
    "\n",
    "        \n",
    "print(len(Series_title),len(Year_span),len(Rating_7),len(Votes_7))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6ee9037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011â€“2019</td>\n",
       "      <td>18</td>\n",
       "      <td>(2.3M)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title  Year span Rating    Votes\n",
       "1    1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "2    1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "3    1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "4    1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "5    1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "..                  ...        ...    ...      ...\n",
       "246  1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "247  1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "248  1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "249  1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "250  1. Game of Thrones  2011â€“2019     18   (2.3M)\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7=pd.DataFrame({\n",
    "    'Title':Series_title,\n",
    "    'Year span':Year_span,\n",
    "    #'Genre':Genre_,\n",
    "    #'Run-time':Run_time,\n",
    "    'Rating':Rating_7,\n",
    "    'Votes':Votes_7\n",
    "})\n",
    "df_7.index=df_7.index + 1 \n",
    "df_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9eab2588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Title</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>2008â€“2013</td>\n",
       "      <td>CrimeDramaThriller</td>\n",
       "      <td>45min</td>\n",
       "      <td>18</td>\n",
       "      <td>9.5\\n/10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series Title  Year Span               Genre Run Time Rating     Votes\n",
       "1    Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "2    Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "3    Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "4    Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "5    Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "..            ...        ...                 ...      ...    ...       ...\n",
       "246  Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "247  Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "248  Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "249  Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "250  Breaking Bad  2008â€“2013  CrimeDramaThriller    45min     18  9.5\\n/10\n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7=pd.DataFrame({\n",
    "    'Series Title' :Dataset_name,\n",
    "    'Data Type' :Data_type,show_250_details)\n",
    "df_7.index=df_7.index + 1 \n",
    "df_7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632535a9",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baee9e0",
   "metadata": {},
   "source": [
    "__8. Details of Datasets from UCI machine learning repositories.   \n",
    "Url = https://archive.ics.uci.edu/  You have to find the following details:   \n",
    "A) Dataset name   B) Data type   C) Task   D) Attribute type   E) No of instances   F) No of attribute G) Year__  \n",
    " \n",
    "      Note: - from the home page you have to go to the Show All Dataset page through code.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "852cef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web driver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "08bce700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open theguardian webpage to be scrapped\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "07c6a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click view_datasets\n",
    "view_=driver.find_element(By.XPATH, \"//div[@class='flex max-w-7xl flex-col gap-6']/div/a[1]\")\n",
    "view_.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "312eae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click expand all\n",
    "expand_all=driver.find_element(By.XPATH, \"//span[@class='swap-on text-primary-content']\")\n",
    "expand_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task_=[]\n",
    "Attribute_type=[]\n",
    "Num_inst=[]\n",
    "Num_att=[]\n",
    "Year_8=[]\n",
    "\n",
    "try:\n",
    "    name_tags=driver.find_elements(By.XPATH, \"//h2[@class='truncate text-primary']\")\n",
    "    for i in name_tags:\n",
    "        Dataset_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "        time.sleep(2)\n",
    "#print Dataset_name\n",
    "print(len(Dataset_name))\n",
    "\n",
    "try:\n",
    "    type_tags=driver.find_elements(By.XPATH, \"//div[@class='col-span-3 flex items-center gap-2'][2]/span\")\n",
    "    for i in type_tags:\n",
    "        Data_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Data_type.append('-')\n",
    "    time.sleep(2)\n",
    "#print Data_type\n",
    "print(len(Data_type))\n",
    "\n",
    "try:\n",
    "    task_tags=driver.find_elements(By.XPATH, \"//div[@class='col-span-3 flex items-center gap-2'][1]/span\")\n",
    "    for i in task_tags:\n",
    "        Task_.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task_.append('-')\n",
    "    time.sleep(2)\n",
    "#print Task_\n",
    "print(len(Task_))\n",
    "\n",
    "try:\n",
    "    att_tags=driver.find_elements(By.XPATH, \"//table[@class='col-span-full my-2 table sm:col-start-2']/tbody/tr/td[2]\")\n",
    "    for i in att_tags:\n",
    "        Attribute_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute_type.append('-')\n",
    "    time.sleep(2)\n",
    "#print Attribute_type\n",
    "print(len(Attribute_type))\n",
    "\n",
    "try:\n",
    "    inst_tags=driver.find_elements(By.XPATH, \"//div[@class='col-span-3 flex items-center gap-2'][3]/span\")\n",
    "    for i in inst_tags:\n",
    "        Num_inst.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Num_inst.append('-')\n",
    "    time.sleep(2)\n",
    "#print Num_int\n",
    "print(len(Num_inst))\n",
    "\n",
    "\n",
    "try:\n",
    "    natt_tags=driver.find_elements(By.XPATH, \"//div[@class='col-span-3 flex items-center gap-2'][4]/span\")\n",
    "    for i in natt_tags:\n",
    "        Num_att.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Num_att.append('-')\n",
    "    time.sleep(2)\n",
    "#print Num_att\n",
    "print(len(Num_att))\n",
    "\n",
    "\n",
    "try:\n",
    "    year_tags=driver.find_elements(By.XPATH, \"//tbody[@class='border']/tr/td[3]\")\n",
    "    for i in year_tags:\n",
    "        Year_8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_8.append('-')\n",
    "    time.sleep(2)\n",
    "\n",
    "    \n",
    "#print year_8\n",
    "print(len(Year_8))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5432a9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Number of instances</th>\n",
       "      <th>Number of Attributes</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6649</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6650</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6650 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Dataset Name     Data Type  \\\n",
       "1                                     Iris       Tabular   \n",
       "2                                 Dry Bean  Multivariate   \n",
       "3                            Heart Disease  Multivariate   \n",
       "4               Rice (Cammeo and Osmancik)  Multivariate   \n",
       "5                                   Raisin  Multivariate   \n",
       "...                                    ...           ...   \n",
       "6646                                 Adult  Multivariate   \n",
       "6647  Breast Cancer Wisconsin (Diagnostic)  Multivariate   \n",
       "6648                                  Wine       Tabular   \n",
       "6649                          Wine Quality  Multivariate   \n",
       "6650                        Bank Marketing  Multivariate   \n",
       "\n",
       "                            Task              Attribute Type  \\\n",
       "1                 Classification                        Real   \n",
       "2                 Classification               Integer, Real   \n",
       "3                 Classification  Categorical, Integer, Real   \n",
       "4                 Classification                        Real   \n",
       "5                 Classification               Real, Integer   \n",
       "...                          ...                         ...   \n",
       "6646              Classification        Categorical, Integer   \n",
       "6647              Classification                        Real   \n",
       "6648              Classification               Integer, Real   \n",
       "6649  Classification, Regression                        Real   \n",
       "6650              Classification        Categorical, Integer   \n",
       "\n",
       "     Number of instances Number of Attributes       Date  \n",
       "1          150 Instances           4 Features   7/1/1988  \n",
       "2       13.61K Instances          16 Features  9/14/2020  \n",
       "3          303 Instances          13 Features   7/1/1988  \n",
       "4        3.81K Instances           7 Features  10/6/2019  \n",
       "5          900 Instances           8 Features  8/14/2023  \n",
       "...                  ...                  ...        ...  \n",
       "6646    48.84K Instances          14 Features   5/1/1996  \n",
       "6647       569 Instances          30 Features  11/1/1995  \n",
       "6648       178 Instances          13 Features   7/1/1991  \n",
       "6649      4.9K Instances          12 Features  10/7/2009  \n",
       "6650    45.21K Instances          17 Features  2/14/2012  \n",
       "\n",
       "[6650 rows x 7 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame \n",
    "\n",
    "\n",
    "df_8=pd.DataFrame({\n",
    "    'Dataset Name' :Dataset_name,\n",
    "    'Data Type' :Data_type,\n",
    "    'Task':Task_,\n",
    "    'Attribute Type':Attribute_type,\n",
    "    'Number of instances':Num_inst,\n",
    "    'Number of Attributes': Num_att,\n",
    "    'Date':Year_8\n",
    "    })\n",
    "#adjust index\n",
    "df_8.index=df_8.index + 1\n",
    "df_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f007b6",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc9883",
   "metadata": {},
   "source": [
    "END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
