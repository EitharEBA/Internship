{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e41944",
   "metadata": {},
   "source": [
    "Eithar Elfatih Burie Abdelrahman Batch DS2403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d22da2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9ee36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fb9547e",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfa938",
   "metadata": {},
   "source": [
    "1.Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cb693",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "40cd0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter required product:men's trousers\n",
      "No more pages to load.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "48d52496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search for: men's trousers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Men Solid Casual Regular Fit Trousers</td>\n",
       "      <td>Men Solid Casual Regular Fit Trousers</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men's Solid Formal Trousers</td>\n",
       "      <td>Men's Solid Formal Trousers</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mens Cotton Lycra Mid Rise Straight Solid Chinos</td>\n",
       "      <td>Mens Cotton Lycra Mid Rise Straight Solid Chinos</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Men's Slim Fit Cargos</td>\n",
       "      <td>Men's Slim Fit Cargos</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Men Trouser || Men's Regular Trouser || Men's ...</td>\n",
       "      <td>Men Trouser || Men's Regular Trouser || Men's ...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/Trouser-Regular-Casual-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Men's Solid Tailored Fit Polyester Formal Trouser</td>\n",
       "      <td>Men's Solid Tailored Fit Polyester Formal Trouser</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/Arrow-Regular-Pants-ARAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Men Cargos</td>\n",
       "      <td>Men Cargos</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Men's Cotton Printed Camoflague Cargo Trouser</td>\n",
       "      <td>Men's Cotton Printed Camoflague Cargo Trouser</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Men's Slim Fit Stretch Trousers (Business Casu...</td>\n",
       "      <td>Men's Slim Fit Stretch Trousers (Business Casu...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>KANU Fashion World Regular Fit Men Trouser_2/3...</td>\n",
       "      <td>KANU Fashion World Regular Fit Men Trouser_2/3...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Brand Name  \\\n",
       "1                Men Solid Casual Regular Fit Trousers   \n",
       "2                          Men's Solid Formal Trousers   \n",
       "3     Mens Cotton Lycra Mid Rise Straight Solid Chinos   \n",
       "4                                Men's Slim Fit Cargos   \n",
       "5    Men Trouser || Men's Regular Trouser || Men's ...   \n",
       "..                                                 ...   \n",
       "176  Men's Solid Tailored Fit Polyester Formal Trouser   \n",
       "177                                         Men Cargos   \n",
       "178      Men's Cotton Printed Camoflague Cargo Trouser   \n",
       "179  Men's Slim Fit Stretch Trousers (Business Casu...   \n",
       "180  KANU Fashion World Regular Fit Men Trouser_2/3...   \n",
       "\n",
       "                                          Product Name Price Return/Exchange  \\\n",
       "1                Men Solid Casual Regular Fit Trousers                     -   \n",
       "2                          Men's Solid Formal Trousers                     -   \n",
       "3     Mens Cotton Lycra Mid Rise Straight Solid Chinos                     -   \n",
       "4                                Men's Slim Fit Cargos                     -   \n",
       "5    Men Trouser || Men's Regular Trouser || Men's ...                     -   \n",
       "..                                                 ...   ...             ...   \n",
       "176  Men's Solid Tailored Fit Polyester Formal Trouser                     -   \n",
       "177                                         Men Cargos                     -   \n",
       "178      Men's Cotton Printed Camoflague Cargo Trouser                     -   \n",
       "179  Men's Slim Fit Stretch Trousers (Business Casu...                     -   \n",
       "180  KANU Fashion World Regular Fit Men Trouser_2/3...                     -   \n",
       "\n",
       "    Expected Delivery Availability  \\\n",
       "1                   -            -   \n",
       "2                   -            -   \n",
       "3                   -            -   \n",
       "4                   -            -   \n",
       "5                   -            -   \n",
       "..                ...          ...   \n",
       "176                 -            -   \n",
       "177                 -            -   \n",
       "178                 -            -   \n",
       "179                 -            -   \n",
       "180                 -            -   \n",
       "\n",
       "                                           Product URL  \n",
       "1    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "2    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "3    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "4    https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "5    https://www.amazon.in/Trouser-Regular-Casual-T...  \n",
       "..                                                 ...  \n",
       "176  https://www.amazon.in/Arrow-Regular-Pants-ARAD...  \n",
       "177  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "178  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "179  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "180  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...  \n",
       "\n",
       "[180 rows x 7 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_amazon_products(search_input, max_pages=3):\n",
    "    amazon_url = \"https://www.amazon.in\"\n",
    "    driver = webdriver.Chrome()  \n",
    "    driver.get(amazon_url)\n",
    "# Call the search function\n",
    "    search_amazon(driver, search_input)  \n",
    "\n",
    "    product_data = []\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        product_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//div[@data-component-type=\"s-search-result\"]'))\n",
    "        )\n",
    "        for element in product_elements:\n",
    "            product_url = element.find_element(By.XPATH, './/a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]').get_attribute('href')\n",
    "            \n",
    "            try:\n",
    "                brand_name = element.find_element(By.XPATH, './/span[@class=\"a-size-base-plus a-color-base a-text-normal\"]').text\n",
    "            except:\n",
    "                brand_name = \"-\"\n",
    "            try:\n",
    "                product_name = element.find_element(By.XPATH, './/span[@class=\"a-size-base-plus a-color-base a-text-normal\"]').text\n",
    "            except:\n",
    "                product_name = \"-\"\n",
    "            try:\n",
    "                product_price = element.find_element(By.XPATH, './/span[@class=\"a-offscreen\"]').text\n",
    "            except:\n",
    "                product_price = \"-\"\n",
    "            try:\n",
    "                return_exchange = element.find_element(By.XPATH, './/div[contains(@aria-label, \"FREE Delivery\")]/following-sibling::div[1]').text\n",
    "            except:\n",
    "                return_exchange = \"-\"\n",
    "            try:\n",
    "                expected_delivery = element.find_element(By.XPATH, './/span[@class=\"a-text-bold\"]').text\n",
    "            except:\n",
    "                expected_delivery = \"-\"\n",
    "            try:\n",
    "                availability = element.find_element(By.XPATH, './/span[contains(text(), \"In stock\") or contains(text(), \"Usually dispatched in\")]').text\n",
    "            except:\n",
    "                availability = \"-\"\n",
    "\n",
    "            product_data.append({\n",
    "                'Brand Name': brand_name,\n",
    "                'Product Name': product_name,\n",
    "                'Price': product_price,\n",
    "                'Return/Exchange': return_exchange,\n",
    "                'Expected Delivery': expected_delivery,\n",
    "                'Availability': availability,\n",
    "                'Product URL': product_url\n",
    "            })\n",
    "\n",
    "        # Check for next page and click if available\n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.XPATH, '//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "            next_page_button.click()\n",
    "            time.sleep(2) \n",
    "        except:\n",
    "            #break the loop\n",
    "            break\n",
    "\n",
    "    driver.quit()  # Close the browser\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_csv(\"amazon_products.csv\", index=False)  # Save to CSV\n",
    "    return df\n",
    "\n",
    "\n",
    "def search_amazon(driver, input_search):\n",
    "    #Use presence_of_element_located\n",
    "    search_box = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"twotabsearchtextbox\"))\n",
    "    )\n",
    "    search_box.send_keys(input_search)\n",
    "    search_box.submit()\n",
    "\n",
    "\n",
    "# Get the search term from the user\n",
    "search_term = input(\"Enter the product to search for: \")\n",
    "\n",
    "# Perform the search and scrape the data\n",
    "product_data_df = scrape_amazon_products(input_search)\n",
    "product_data_df.index=product_data_df.index+1\n",
    "product_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63f2d7",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256b498",
   "metadata": {},
   "source": [
    "3.Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "80753a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 images for \"fruits\" :\n",
      "1. https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png\n",
      "2. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSfXdjbHBJX06KUKN4tkfd8KFFDyYnIICCvDxYxgY3_0Plx7p71-aCeB-fp&s\n",
      "3. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQhRe8IDwbhaqr66uyVbS3Mcn8qLL5bqhVNrKr19LhFvDtTE3wmthx8m3Zx&s\n",
      "4. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJI-r9JDFn4sJnHXt76kL8lBBybGhtbRz3ArtMtSSGdocJlaSoA2sZPze4&s\n",
      "5. https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg\n",
      "6. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRb8pOojAEhqtRfCks1g-qoZQStlPtMbDrJ-Q&s\n",
      "7. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQXPbFb9nYxZTmrHzr3SpbS4fYQlq1rDLDhAg&s\n",
      "8. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSI-UzsUzLpfTKFBJPysBoJDQqiS1w1SYDzeg&s\n",
      "9. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQiTNyEzEUByF7Z2Hp8CmS8Va721UxKICTpEQ&s\n",
      "10. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQQ8ZX1beBSP-ydVjHGJdSiHCBnurQycP6IPw&s\n",
      "\n",
      "Top 10 images for \"cars\" :\n",
      "1. https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png\n",
      "2. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTwqM2a8Zbso53YHmCDOkFkALarT5Jo8ac9Jd98gCjCtyUSFN9VRTgZY41e&s\n",
      "3. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT-qtWBa7NHBH0hAU0aApELB3AalJb8mCcYrK-UjT3m-MNX10VqKxF4uvsP&s\n",
      "4. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTYLLWchCxJHeX75F7LfyYrkW7HcE3U3vtrVtB31FOo3ZBRtI-CFnEHx-0x&s\n",
      "5. https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg\n",
      "6. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRBvb2Yiwa2VaY1JDupBMOBgMgGg-IGGLaTyw&s\n",
      "7. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ722AXEoYgu5H-F_NpetNnr5G0WM11a6t3OQ&s\n",
      "8. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcScUmp60a9OgQnlJYMsxhj9bNVpSK9-SoK22w&s\n",
      "9. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPhrqVBpJ_WhombkRBHwb5IXeKCE59l5Ip2g&s\n",
      "10. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT8KVoEs0mgMs16l2K3tfqHYC38DezlJJ5ySQ&s\n",
      "\n",
      "Top 10 images for \"Machine Learning\" :\n",
      "1. https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png\n",
      "2. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRlIYztY73MIZJMoZs_yizHYW8FXD5eVL7Z77nrLEd8aRl_EnDLBAM0p2JR&s\n",
      "3. https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg\n",
      "4. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvXsAMbAyJF9ul9A5XyfFUDfIWECamelcbUQ&s\n",
      "5. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRBmkwAUDjC1skTs0AK0lqkpR-qoMHynxT-EA&s\n",
      "6. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsU_LADrPxKuU1kK4eRYTXca5ckswpqnxAJw&s\n",
      "7. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTu6viiR8wv9ykc_DpOx7J4-j4ORWSjT8BmrA&s\n",
      "8. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ-L5qb4S-8PiD4yjsSRoP4hy5CQik8XxSIKw&s\n",
      "9. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR3Hkyz-NurUMh656WSOyk5DdBHJZZUh2sFZg&s\n",
      "10. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTsVcX0qEBAK5JneMIyokrvUA2iDujBnmGhJg&s\n",
      "\n",
      "Top 10 images for \"Guitar\" :\n",
      "1. https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png\n",
      "2. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQZoU-gzrrZSNu29a9gzYsr0aeyeTStMlCrOsRXilNNs-bP5z8JpI2ZPEi5&s\n",
      "3. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTMEw30MW9Y0aibSsX4ys0i0CEvqd6d3PXRTGxMmC78F9I1rU1tRs8fmzle&s\n",
      "4. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRXUusny0oNa6bJVhJyif3Dk6I0o1e3MnyGFHAywezCawfdyGmsLy6NonHw&s\n",
      "5. https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg\n",
      "6. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSpWaF7SyTf6Fj7uexn8TX2BDFPUhFvQg5krA&s\n",
      "7. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcStuON-Iqo0ZPfN5w3-nQdy4Zy6VlH5Fo1t3A&s\n",
      "8. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSmmxrK3RKpn3O_i8gcDIsLi3mPn6La_XVuWg&s\n",
      "9. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRR90zZUKEooCpFyRmUCRbMfyrmrUnl80af5w&s\n",
      "10. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmCjPe8f6QlUsyH2xcl7cFN-gcyC9FOANYAQ&s\n",
      "\n",
      "Top 10 images for \"Cakes\" :\n",
      "1. https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png\n",
      "2. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRC9ZFacv0YnSuJpa42HRRcdGBa-DnGZxH16OPHuJNRGsXH6B9uYU_vYLHH&s\n",
      "3. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTO_fdaR0q6b2VH4QHMQg0N1rZKlP6t1tyk_qy5WUhkflWWf_t3K3IYLfQT&s\n",
      "4. https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg\n",
      "5. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT3GmNs7UghBZZkSV7ZQtvPXlpSEj1KhQU1Fg&s\n",
      "6. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQIXfdGloO33dNDZR1snPrO7TZPTk8HvgxPAg&s\n",
      "7. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTCM2xQEKiu1qCO9B5puGsncaEVsS00ZsQPhA&s\n",
      "8. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR5qqfpU2_EN43ONCWDr12Yp88DPxcSDac9wg&s\n",
      "9. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTtJrizB9KIxq6E-J8PIaFkSR0giaDwXyYQsQ&s\n",
      "10. https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRdeO8LafAhMNAi274ol5P6r5Ojkv5pjh3R5g&s\n"
     ]
    }
   ],
   "source": [
    "# Create a new chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#create keywords list\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "\n",
    "for keyword in keywords:\n",
    "    # Open images.google.com\n",
    "    driver.get('https://images.google.com')\n",
    "\n",
    "    #find search bar. enter keywords\n",
    "    search_=driver.find_element(By.XPATH, \"//textarea[@class='gLFyf']\")\n",
    "    search_.send_keys(keyword)\n",
    "    \n",
    "    button_=driver.find_element(By.XPATH, \"//button[@class='Tg7LZd']\")\n",
    "    button_.click()\n",
    "    \n",
    "    #scroll to load more images\n",
    "    for _ in range(3):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(5)\n",
    "    \n",
    "    #find image details,extract urls \n",
    "    image_dets=driver.find_elements(By.TAG_NAME, 'img')\n",
    "    image_urls=[element.get_attribute('src') for element in image_dets]\n",
    "    image_urls=[url for url in image_urls if url and url.startswith('https')]\n",
    "    \n",
    "    #print first ten\n",
    "    \n",
    "    print(f'\\nTop 10 images for \"{keyword}\" :')\n",
    "    for i in range(min(10, len(image_urls))):\n",
    "        print(f'{i+1}. {image_urls[i]}')\n",
    "\n",
    "#close driver           \n",
    "driver.quit()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79174ea8",
   "metadata": {},
   "source": [
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e997a8",
   "metadata": {},
   "source": [
    "4.Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,  \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2548c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com')\n",
    "\n",
    "# enter keyword into sesrch bar and click \n",
    "designation=driver.find_element(By.XPATH, \"//input[@class='Pke_EE']\")\n",
    "designation.send_keys(\"Samsung Galaxy S23\")\n",
    "\n",
    "#\n",
    "search=driver.find_element(By.XPATH, \"//button[@class='_2iLD__']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8ce8d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmartPhoneNameAndColour=[]\n",
    "RAM=[]\n",
    "StorageROM=[]\n",
    "PrimeCam=[]\n",
    "SecondCam=[]\n",
    "DisplaySize=[]\n",
    "BatteryCapacity=[]\n",
    "Price=[]\n",
    "ProductURL=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c3f03743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap SmartPhoneNameAndColour\n",
    "name_tags=driver.find_elements(By.XPATH, \"//div[@class='KzDlHZ']\")\n",
    "for i in name_tags:\n",
    "    name=i.text\n",
    "    SmartPhoneNameAndColour.append(name)\n",
    "    \n",
    "# scrap RAM\n",
    "RAM_tags=driver.find_elements(By.XPATH, \".//ul[@class='G4BRas']\")\n",
    "for i in RAM_tags:\n",
    "    ram=i.text\n",
    "    RAM.append(ram)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4405f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "#check length of all details are equal for Dataframe to be created \n",
    "print(len(SmartPhoneNameAndColour),len(RAM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb720b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43025f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a2d808a",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558b7fd",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6debf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter city: Nasr City \n",
      "Url Extracted: https://www.google.com/maps/place/Nasr+City,+Al+Manteqah+Al+Oula,+Nasr+City,+Cairo+Governorate+4450113/@30.1254945,31.3198379,15z/data=!4m6!3m5!1s0x14583e5d94c66301:0xddddf100de42206c!8m2!3d30.0566104!4d31.3301076!16s%2Fg%2F11xcyk3j2?entry=ttu\n",
      "Latitude = 30.1254945, Longitude= 31.3198379\n"
     ]
    }
   ],
   "source": [
    "#open goole maps on automated chrome\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.google.com/maps\")\n",
    "time.sleep(5)\n",
    "\n",
    "city=input('Enter city: ')\n",
    "\n",
    "designation=driver.find_element(By.ID, \"searchboxinput\")\n",
    "designation.send_keys(city)\n",
    "time.sleep(5)\n",
    "\n",
    "search=driver.find_element(By.ID, \"searchbox-searchbutton\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "try:\n",
    "    url_=driver.current_url\n",
    "    print(\"Url Extracted:\", url_)\n",
    "    lat_long=re.findall(r'@(.*)data',url_)\n",
    "    if len(lat_long):\n",
    "        lat_long_= lat_long[0].split(\",\")\n",
    "        if len(lat_long_)>=2:\n",
    "            lat=lat_long_[0]\n",
    "            long=lat_long_[1]\n",
    "        print(\"Latitude = {}, Longitude= {}\".format(lat, long))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Error\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2d537",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ee669",
   "metadata": {},
   "source": [
    "6.Write a program to scrap all the available details of best gaming laptops from digit.in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a037e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed32da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[1]/div/div/div[2]/form/input[1]\")\n",
    "designation.send_keys(\"gaming laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770eaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570baed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2cf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65200b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70768f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "215b5dee",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd78099",
   "metadata": {},
   "source": [
    "7.Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e3052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5100ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open chrome \n",
    "driver=webdriver.Chrome()\n",
    "#load required webpage\n",
    "driver.get('https://www.forbes.com/billionaires/')\n",
    "\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686873c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "NetWorth=[]\n",
    "Age=[]\n",
    "CountryTerritory=[]\n",
    "Source=[]\n",
    "Industry=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ee0612",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WebElement' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ranks\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTable_rank__X4MKf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/div\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ranks:\n\u001b[0;32m      3\u001b[0m     Rank\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m      5\u001b[0m timesleep(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WebElement' object is not iterable"
     ]
    }
   ],
   "source": [
    "ranks=driver.find_element(By.XPATH, \"//div[@class='Table_rank__X4MKf']/div\")\n",
    "for i in ranks:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "names=driver.find_element(By.XPATH, \"//div[@class='Table_personName__Bus2E']\")\n",
    "for i in names:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "net_=driver.find_element(By.XPATH, \"//div[@class='Table_finalWorth__UZA6k']\")\n",
    "for i in net_:\n",
    "    NetWorth.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "age=driver.find_element(By.XPATH, \"//div[@role='cell']//span\")\n",
    "for i in age:\n",
    "    Age.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "country=driver.find_element(By.XPATH, \"\")\n",
    "for i in country:\n",
    "    CountryTerritory.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "sources=driver.find_element(By.XPATH, \"//div[@class='Table_columnHeader__Js_Vi']\")\n",
    "for i in sources:\n",
    "    Source.append(i.text)\n",
    "    \n",
    "timesleep(2)\n",
    "\n",
    "industry=driver.find_element(By.XPATH, \"\")\n",
    "for i in industry:\n",
    "    Industry.append(i.text)\n",
    "    \n",
    "timesleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86c1c1",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61624ea9",
   "metadata": {},
   "source": [
    "8.Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "594a4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open chrome webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.youtube.com/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e55a52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for search bar\n",
    "search_bar = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/form/div[1]/div[1]/input')\n",
    "search_bar.send_keys(\"beyonce - crazy in love\") \n",
    "time.sleep(1)\n",
    "\n",
    "#clicking on search button\n",
    "search_btn = driver.find_element(By.ID, \"search-icon-legacy\")  \n",
    "search_btn.click()\n",
    "time.sleep(4)\n",
    "\n",
    "#clicking on first video\n",
    "link_click = driver.find_element(By.XPATH, \"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[2]/div[1]/div/div[1]/div/h3/a\")\n",
    "link_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5e339f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract comments, upvotes and time\n",
    "comment=[]\n",
    "comment_date=[]\n",
    "up_vote=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34ed561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scroll to comments\n",
    "scroll_time= 2 #seconds\n",
    "scrolls= 15\n",
    "\n",
    "for i in range(scrolls):\n",
    "    driver.execute_script('window.scrollTo(0,document.documentElement.scrollHeight);')\n",
    "    time.sleep(scroll_time)\n",
    "    \n",
    "\n",
    "\n",
    "    comments=driver.find_elements(By.XPATH, \"//div[@class='style-scope ytd-expander']/yt-attributed-string\")\n",
    "    for i in comments:\n",
    "        if i.text is None:\n",
    "            comment.append('--')\n",
    "        else:\n",
    "            comment.append(i.text)\n",
    "    time.sleep(2)\n",
    "\n",
    "    upvotes=driver.find_elements(By.XPATH, \"//span[@class='style-scope ytd-comment-engagement-bar']\")\n",
    "    for i in upvotes:\n",
    "        up_vote.append(i.text)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    \n",
    "    times=driver.find_elements(By.XPATH, \"//span[@id='published-time-text']\")\n",
    "    for i in times:\n",
    "        comment_date.append(i.text)\n",
    "    \n",
    "    for i in range(0,len(comment_date),2):\n",
    "        comment_date.append(comment_date[i])\n",
    "        \n",
    "    time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2fd51f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(comments), len(upvotes), len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a832261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment Time</th>\n",
       "      <th>Up vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Comment, Comment Time, Up vote]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube=pd.DataFrame({'Comment':comment[0:500],\n",
    "                'Comment Time': comment_date[0:500],\n",
    "                'Up vote': up_vote[0:500]})\n",
    "df_youtube.index=df_youtube.index +1\n",
    "df_youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f987b",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4771bdb",
   "metadata": {},
   "source": [
    "9.Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.hostelworld.com/')\n",
    "\n",
    "#find and enter 'london for location\n",
    "location=driver.find_element(By.XPATH, \"//input[@class='native-input']\")\n",
    "location.send_keys('London')\n",
    "time.sleep(2)\n",
    "\n",
    "#\n",
    "location2=driver.find_element(By.XPATH, \"/html/body/div[3]/div/div[2]/main/header/div/div[2]/div[1]/div[1]/div/div[1]/div[2]/div/ul/li[2]/button\")\n",
    "location2.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#find and click search\n",
    "search=driver.find_element(By.XPATH, \"/html/body/div[3]/div/div[2]/main/header/div/div[2]/div[1]/div[1]/div/div[5]/button[1]\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251749c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all hostel containers \n",
    "hostel=driver.find_elements(By.XPATH, \"//div[@class='property-card']\"\n",
    "\n",
    "for hostel in hostels:\n",
    "    try:\n",
    "        name="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists\n",
    "hostel_name=[]\n",
    "distance_=[]\n",
    "ratings_=[]\n",
    "tot_reviews=[]\n",
    "overall_review=[]\n",
    "private_price=[]\n",
    "dorm_price=[]\n",
    "facilities_=[]\n",
    "prop_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping hostel_name from given page\n",
    "name_tags=driver.find_elements(By.XPATH, \"//div[@class='property-name']/span\") \n",
    "for i in name_tags:\n",
    "    name=i.text\n",
    "    hostel_name.append(name)\n",
    "   \n",
    "#scraping distance from given page\n",
    "distance_tags=driver.find_elements(By.XPATH, \"//span[@class='distance-description']\") \n",
    "for i in distance_tags:\n",
    "    distance=i.text\n",
    "    distance_.append(distance)\n",
    "\n",
    "#scraping ratings from given page\n",
    "ratings_tags=driver.find_elements(By.XPATH, \"//div[@class='rating medium theme-null']\") \n",
    "for i in ratings_tags:\n",
    "    rating=i.text\n",
    "    ratings_.append(ratings)\n",
    "    \n",
    "#scraping ratings from given page\n",
    "total_tags=driver.find_elements(By.XPATH, \"//div[@class='rating medium theme-null']\") \n",
    "for i in total_tags:\n",
    "    total=i.text\n",
    "    tot_review.append(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd029bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6755c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
